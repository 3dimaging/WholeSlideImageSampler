{
    "docs": [
        {
            "location": "/",
            "text": "Whole-Slide-Image sampler\n\n\nGitHub\n, \nDocs\n. (Docs autogenerated with \npydocmd\n. \nTo do: Images not working on docs.\n)\n\n\nThis respository aims to develop a tool for sampling from Whole-Slide-Images (WSIs) in an efficient manner. By sampling we mean producing mini-batches of patches which can then be fed to e.g. machine learning algorithms. It aims to work with all WSIs that can be read by \nopenslide\n. Sample data for demos is available \nhere\n (from \nCamelyon 16\n dataset).\n\n\nWhen sampling patches we would like to be able to assign a class label (e.g. a binary label with normal==0 vs cancer==1). This is facilitated by adding a multi-resolution annotation mask. WSI annotations can be made efficiently with a program such as \nASAP\n and are often stored as xml files (see the \nsample data\n for example). These in turn can be converted to the multi-resolution annotation masks we want. \nTo do: Detail how to achieve this!\n\n\nSome features:\n\n\n\n\nmodules.slide_sampler.Slide_Sampler()\n\n\n\n\nUsed to sample patches from a WSI. We can generate a background mask or add a binary multi-resolution annotation mask:\n\n\nleft: WSI, middle: generated background mask, right: added annotation mask.\n\n\nTo do: CHECK annotation as xml files seems to have multiple regions!?\n\n\n\n\nWe can sample patches from the different classes:\n\n\nclass 0. 256x256 patches at 10X (downsampling of 4.0).\n\n\n\n\nclass 1. 256x256 patches at 10X (downsampling of 4.0).\n\n\nTo do: CHECK are these really cancer?!\n\n\n\n\nWe can also generate a basic \npatchframe\n with this class. A patchframe is defined as a datastructure containing coordinates of patches as well as metadata like the patch class and also the patch parent WSI, size, level. Note that the patches themselves are not stored! At present this is implemented with a pd.DataFrame and it is estimated that 100,000 could be represented in this way using a memory of only a few MB on disk.\n\n\ne.g.\n\n\n'''\npatchframe head:\n       w       h class                                             parent level size\n0  30900  119768     0  /home/peter/Dropbox/publish-final/WSI_sampler_...     2  256\n1  78691  170619     0  /home/peter/Dropbox/publish-final/WSI_sampler_...     2  256\n2  67651  158458     0  /home/peter/Dropbox/publish-final/WSI_sampler_...     2  256\n3  65468  156771     0  /home/peter/Dropbox/publish-final/WSI_sampler_...     2  256\n4  40402  115702     0  /home/peter/Dropbox/publish-final/WSI_sampler_...        2  256\n\n\n'''\n\n\nWe can get hard copies of the patches in a patchframe for viewing with e.g. 'modules.utils.save_patchframe_patches()'.",
            "title": "Home"
        },
        {
            "location": "/#whole-slide-image-sampler",
            "text": "GitHub ,  Docs . (Docs autogenerated with  pydocmd .  To do: Images not working on docs. )  This respository aims to develop a tool for sampling from Whole-Slide-Images (WSIs) in an efficient manner. By sampling we mean producing mini-batches of patches which can then be fed to e.g. machine learning algorithms. It aims to work with all WSIs that can be read by  openslide . Sample data for demos is available  here  (from  Camelyon 16  dataset).  When sampling patches we would like to be able to assign a class label (e.g. a binary label with normal==0 vs cancer==1). This is facilitated by adding a multi-resolution annotation mask. WSI annotations can be made efficiently with a program such as  ASAP  and are often stored as xml files (see the  sample data  for example). These in turn can be converted to the multi-resolution annotation masks we want.  To do: Detail how to achieve this!  Some features:   modules.slide_sampler.Slide_Sampler()   Used to sample patches from a WSI. We can generate a background mask or add a binary multi-resolution annotation mask:  left: WSI, middle: generated background mask, right: added annotation mask.  To do: CHECK annotation as xml files seems to have multiple regions!?   We can sample patches from the different classes:  class 0. 256x256 patches at 10X (downsampling of 4.0).   class 1. 256x256 patches at 10X (downsampling of 4.0).  To do: CHECK are these really cancer?!   We can also generate a basic  patchframe  with this class. A patchframe is defined as a datastructure containing coordinates of patches as well as metadata like the patch class and also the patch parent WSI, size, level. Note that the patches themselves are not stored! At present this is implemented with a pd.DataFrame and it is estimated that 100,000 could be represented in this way using a memory of only a few MB on disk.  e.g.  '''\npatchframe head:\n       w       h class                                             parent level size\n0  30900  119768     0  /home/peter/Dropbox/publish-final/WSI_sampler_...     2  256\n1  78691  170619     0  /home/peter/Dropbox/publish-final/WSI_sampler_...     2  256\n2  67651  158458     0  /home/peter/Dropbox/publish-final/WSI_sampler_...     2  256\n3  65468  156771     0  /home/peter/Dropbox/publish-final/WSI_sampler_...     2  256\n4  40402  115702     0  /home/peter/Dropbox/publish-final/WSI_sampler_...        2  256  '''  We can get hard copies of the patches in a patchframe for viewing with e.g. 'modules.utils.save_patchframe_patches()'.",
            "title": "Whole-Slide-Image sampler"
        },
        {
            "location": "/slide_sampler/",
            "text": "modules.slide_sampler\n\n\n\nslide_sampler module\n\n\nSlide_Sampler\n\n\n\nSlide_Sampler(self, wsi_file, desired_downsampling, size)\n\n\n\n\nA Whole-Slide-Image (WSI) patch sampler. Samples patches of user defined size at a desired downsampling.\n\n\nImportant are:\n\n\n\n\nself.wsi\n : an OpenSlide object of the multi-resolution WSI specified by wsi_file.\n\n\nself.background_mask\n : a background mask (generate with self.generate_background_mask()). Stored as a np.ndarray where 1.0 denotes tissue.\n\n\nself.annotation_mask\n : a multi-resolution binary annotation mask. Must have a level with the desired downsampling else WSI and annotation mask incompatible.\n\n\n\n\nParameters\n\n\n\n\nwsi_file\n: path to a WSI readable by openslide\n\n\ndesired_downsampling\n: the desired downsampling for patches\n\n\nsize\n: the requested size for patches\n\n\n\n\nget_classed_patch\n\n\n\nSlide_Sampler.get_classed_patch(self, patch_class=None, verbose=0)\n\n\n\n\nGet a random, classed patch from the WSI.\nAccept if over 90% is non-background and belonging to a single class.\nCan specify desired class or just leave as None to get either.\n\nAlso returns an info dict with w and h coordinates, class and other data needed for reading patch\n.\n\n\nget_patch\n\n\n\nSlide_Sampler.get_patch(self, with_info=0)\n\n\n\n\nGet a random patch from the WSI.\nAccept if over 90% is non-background.\n\nAlso returns an info dict with w and h coordinates if with_info==1\n.\n\n\npickle_load_background_mask\n\n\n\nSlide_Sampler.pickle_load_background_mask(self, file)\n\n\n\n\nLoad a background mask and meta data\n\n\nget_basic_patchframe\n\n\n\nSlide_Sampler.get_basic_patchframe(self, number_patches, save=0, savedir='/home/peter/projects_/slide_loader/docs_builder')\n\n\n\n\nGet a basic patchframe (pd.DataFrame) for N = number_patches patches. If save==True then save the patchframe with pickle.\n\n\ncheck_patch\n\n\n\nSlide_Sampler.check_patch(self, x)\n\n\n\n\nDivide by 255.0 if x.max > 1.0. And ensure float.\n\n\nsave_WSI_thumbnail\n\n\n\nSlide_Sampler.save_WSI_thumbnail(self, dir='/home/peter/projects_/slide_loader/docs_builder')\n\n\n\n\nSave a thumbnail of the WSI\n\n\nlevel_converter\n\n\n\nSlide_Sampler.level_converter(self, x, lvl_in, lvl_out, round=1)\n\n\n\n\nConvert a coordinate 'x' at lvl_in from lvl_in to lvl_out\n\n\nsave_annotation_thumbnail\n\n\n\nSlide_Sampler.save_annotation_thumbnail(self, dir='/home/peter/projects_/slide_loader/docs_builder')\n\n\n\n\nSave a thumbnail visualizing the annotation\n\n\nsave_background_mask_visualization\n\n\n\nSlide_Sampler.save_background_mask_visualization(self, dir='/home/peter/projects_/slide_loader/docs_builder')\n\n\n\n\nSave a visualization of the background mask.\n\n\npickle_background_mask\n\n\n\nSlide_Sampler.pickle_background_mask(self, dir='/home/peter/projects_/slide_loader/docs_builder')\n\n\n\n\nSave the background mask and meta data\n\n\nget_level_and_downsampling\n\n\n\nSlide_Sampler.get_level_and_downsampling(self, mri, desired_downsampling, threshold)\n\n\n\n\nGet the level and downsampling for a desired downsampling.\nA threshold is used to allow for not exactly equal desired and true downsampling.\nIf an appropriate level is not found an exception is raised.\n\n\nParameters\n\n\n\n\nmri\n: A multi-resolution-image OpenSlide object\n\n\n\n\nadd_annotation_mask\n\n\n\nSlide_Sampler.add_annotation_mask(self, annotation_mask_file)\n\n\n\n\nAdd a multi-resolution annotation mask. For compatibility must have a level with the desired downsampling.\n\n\nprint_slide_properties\n\n\n\nSlide_Sampler.print_slide_properties(self)\n\n\n\n\nPrint some WSI properties\n\n\ngenerate_background_mask\n\n\n\nSlide_Sampler.generate_background_mask(self, desired_downsampling=32, threshold=4, disk_radius=10)\n\n\n\n\nGenerate a \nbackground mask\n (np.ndarray). That is a binary (0.0 vs 1.0), downsampled image where 1.0 denotes a tissue region.\nThis is achieved by otsu thresholding on the saturation channel followed by morphological closing and opening to remove noise.\nThe mask desired downsampling factor has a default of 32. For a WSI captured at 40X this corresponds to 1.25X.\nA moderate threshold is used to account for the fact that the desired downsampling may not be available.\nIf an appropriate level is not found an exception is raised.\n\n\nBuilds\n\n\n\n\nself.background_mask : binary (0.0 vs 1.0) np.ndarray.\n\n\n...",
            "title": "slide_sampler"
        },
        {
            "location": "/utils/",
            "text": "modules.utils\n\n\n\nutils module\n\n\nsave_patchframe_patches\n\n\n\nsave_patchframe_patches(input, save_dir)\n\n\n\n\nFor viewing hard copies of the patches in a patch frame.\n\nInput should be a patchframe or a path to a pickled patchframe\n.",
            "title": "utils"
        }
    ]
}